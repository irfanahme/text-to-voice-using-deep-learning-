{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'flask_cors'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a073f88d3a69>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mflask_cors\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcross_origin\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'flask_cors'"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from flask import Flask, jsonify, request, render_template\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "from flask_cors import cross_origin\n",
    "import random\n",
    "import numpy as np\n",
    "from scipy.io.wavfile import write\n",
    "import glob\n",
    "import sys\n",
    "import os\n",
    "from pydub import AudioSegment\n",
    "from currencies import *\n",
    "from math_smybols import *\n",
    "app = Flask(__name__)\n",
    "\n",
    "from data_load import *\n",
    "\n",
    "\n",
    "def load_data2(text):\n",
    "        char2idx, idx2char = load_vocab()\n",
    "        line = text\n",
    "        #print(lines)\n",
    "        \n",
    "        print(char2idx)\n",
    "        sents = [text_normalize(line).strip() + \"E\"] # text normalization, E: EOSa\n",
    "        #print(sents)\n",
    "        texts = np.zeros((len(sents), hp.max_N), np.int32)\n",
    "        for i, sent in enumerate(sents):\n",
    "            texts[i, :len(sent)] = [char2idx[char] for char in sent]\n",
    "        return texts\n",
    "\n",
    "\n",
    "def digit_to_text(text):\n",
    "    import inflect\n",
    "    p = inflect.engine()\n",
    "    pp = '[\\d]+[,\\d]+|[\\d]*[.][\\d]+|[\\d]+'\n",
    "    if re.search(pp, text) is not None:\n",
    "        for catch in re.finditer(pp, text):\n",
    "            #print(catch[0])\n",
    "            t = catch[0]\n",
    "            t= t.replace(',', \"\")\n",
    "            m = re.search(catch[0], text)\n",
    "            try:\n",
    "                tt = int(t)\n",
    "            except:\n",
    "                tt = float(t)\n",
    "            #s.replace(t, \"happy\" )\n",
    "\n",
    "            #tt= int(t)\n",
    "\n",
    "            word = p.number_to_words(tt)\n",
    "            #print(word)\n",
    "            #global str\n",
    "            #ttt = str(tt)\n",
    "            a, b = m.span()\n",
    "            #print(text)\n",
    "            text = text[:a] +  text[a:b].replace(catch[0], word)+ text[b:]# catch is a match object\n",
    "\n",
    "            #text = text.replace(catch[0], word)# catch is a match object\n",
    "    return text\n",
    "def change_chucks(text):\n",
    "    tt = text.split('.')\n",
    "    print(tt)\n",
    "    for i in range(len(tt)):\n",
    "        #print(len(tt[i]))\n",
    "        if len(tt[i]) > 230:\n",
    "            print('help')\n",
    "            if \".\" in tt[i]:\n",
    "                pass\n",
    "\n",
    "            else:\n",
    "                print('open')\n",
    "                print(len(tt[i]))\n",
    "                t = tt[i].split(' ')\n",
    "                print(len(t))\n",
    "                s = int(len(t)/1.5)\n",
    "                print(s)\n",
    "\n",
    "                tt[i] = ' '.join(t[:s]) +'. ' +' '.join(t[s:])\n",
    "                \n",
    "                #print(i)\n",
    "            #text = text[:230] + '.' + text[230:]\n",
    "    print(tt)\n",
    "    text = '.'.join(tt) \n",
    "    return text\n",
    "import os\n",
    "#import pdb\n",
    "from hyperparams import Hyperparams as hp\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from train import Graph\n",
    "from utils import *\n",
    "from data_load import load_data\n",
    "from scipy.io.wavfile import write\n",
    "from tqdm import tqdm\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"6\"\n",
    "#from __future__ import print_function\n",
    "\n",
    "# Load graph\n",
    "g = Graph(mode=\"synthesize\"); print(\"Graph loaded\")\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "# Restore parameters\n",
    "var_list = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'Text2Mel')\n",
    "saver1 = tf.train.Saver(var_list=var_list)\n",
    "saver1.restore(sess, tf.train.latest_checkpoint(hp.logdir + \"-1\"))\n",
    "print(\"Text2Mel Restored!\")\n",
    "\n",
    "var_list = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'SSRN') + \\\n",
    "           tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, 'gs')\n",
    "saver2 = tf.train.Saver(var_list=var_list)\n",
    "saver2.restore(sess, tf.train.latest_checkpoint(hp.logdir + \"-2\"))\n",
    "print(\"SSRN Restored!\")\n",
    "\n",
    "@app.route(\"/voiceover2\")\n",
    "@cross_origin()\n",
    "def voice():\n",
    "    return render_template(\"index.html\")\n",
    "@app.route(\"/get_audio__\",methods = ['POST','OPTIONS'])\n",
    "@cross_origin()\n",
    "def audio__():\n",
    "    text_ = request.form\n",
    "    text = text_['text_voice']\n",
    "#    text = text +\". \"   \n",
    "    text = text.replace('“', '').replace('”', '')\n",
    "    text = digit_to_text(text)\n",
    "    texts = [chunk.strip() for chunk in text.split('\"') if chunk.strip() != '']\n",
    "    print(text)\n",
    "    if len(text)>500:\n",
    "        L = text[:500]\n",
    "    Y = np.zeros((len(L), hp.max_T, hp.n_mels), np.float32)\n",
    "    prev_max_attentions = np.zeros((len(L),), np.int32)\n",
    "    for j in tqdm(range(hp.max_T)):\n",
    "        _gs, _Y, _max_attentions, _alignments = \\\n",
    "            sess.run([g.global_step, g.Y, g.max_attentions, g.alignments],\n",
    "                     {g.L: L,\n",
    "                      g.mels: Y,\n",
    "                      g.prev_max_attentions: prev_max_attentions})\n",
    "        Y[:, j, :] = _Y[:, j, :]\n",
    "        prev_max_attentions = _max_attentions[:, j]\n",
    "    Z = sess.run(g.Z, {g.Y: Y})\n",
    "\n",
    "    # Generate wav files\n",
    "    if not os.path.exists(hp.sampledir): os.makedirs(hp.sampledir)\n",
    "    output = \"\"\n",
    "    for i, mag in enumerate(Z):\n",
    "        print(\"Working on file\", i+1)\n",
    "        wav = spectrogram2wav(mag)\n",
    "        write('/raid/data/data/VC/dc_tts/static' + \"/{}.wav\".format(i+1), hp.sr, wav)\n",
    "        output =str(i)\n",
    "    return output\n",
    "\n",
    "        \n",
    "@app.route(\"/get_audio\",methods = ['POST','OPTIONS'])\n",
    "@cross_origin()\n",
    "def audio_():\n",
    "    os.system('rm /raid/data/data/VC/dc_tts/samples/audios/*.wav')\n",
    "    #os.system('rm /home/stock/jupyter_notebook/DeepLearningExamples/PyTorch/SpeechSynthesis/Tacotron2/static/generated/*')\n",
    "    text_ = request.form\n",
    "    text = text_['text_voice']\n",
    "#    text = text +\". \"a\n",
    "    #pdb.set_trace()\n",
    "    #text = text.replace(' \"', \" \")a\n",
    "    text = text.replace('“', '').replace('”', '')\n",
    "    print(text)\n",
    "    text = symbols_to_text(text)\n",
    "    text = math_symbols_to_text(text)\n",
    "    text = digit_to_text(text)\n",
    "    text = change_chucks(text)\n",
    "    print(text)\n",
    "    chunks = [chunk.strip() for chunk in text.replace('\\n','.').split('.') if chunk.strip() != '']\n",
    "    print(chunks)\n",
    "    for idx,text in enumerate(chunks):\n",
    "        #print(text)\n",
    "        #if len(text) > 230:\n",
    "        #text = text[:230]+'.'+text[230:]\n",
    "          \n",
    "        L = load_data2(text)\n",
    "        #print(L)\n",
    "        #print(L)\n",
    "        Y = np.zeros((len(L), hp.max_T, hp.n_mels), np.float32)\n",
    "        prev_max_attentions = np.zeros((len(L),), np.int32)\n",
    "        #print(prev_max_attentions)\n",
    "        for j in tqdm(range(hp.max_T)):\n",
    "            _gs, _Y, _max_attentions, _alignments = \\\n",
    "                sess.run([g.global_step, g.Y, g.max_attentions, g.alignments],\n",
    "                         {g.L: L,\n",
    "                          g.mels: Y,\n",
    "                          g.prev_max_attentions: prev_max_attentions})\n",
    "            Y[:, j, :] = _Y[:, j, :]\n",
    "            prev_max_attentions = _max_attentions[:, j]\n",
    "\n",
    "        Z = sess.run(g.Z, {g.Y: Y})\n",
    "\n",
    "        # Generate wav files\n",
    "        if not os.path.exists(hp.sampledir): os.makedirs(hp.sampledir)\n",
    "        if not os.path.exists('/raid/data/data/VC/dc_tts/static' +\"/audios/\"): os.makedirs('/raid/data/data/VC/dc_tts/static' +\"/audios/\")\n",
    "        for i, mag in enumerate(Z):\n",
    "            print(\"Working on file\", i)\n",
    "            wav = spectrogram2wav(mag)\n",
    "            write('/raid/data/data/VC/dc_tts/static' + \"/audios/{}.wav\".format(str(idx)), hp.sr, wav)\n",
    "\n",
    "        #os.system('ls /home/stock/jupyter_notebook/DeepLearningExamples/PyTorch/SpeechSynthesis/Tacotron2/static/audios/')\n",
    "        #os.system(\"mv /home/stock/jupyter_notebook/DeepLearningExamples/PyTorch/SpeechSynthesis/Tacotron2/tts_audio/*.wav static/{}.wav\".format(output_name))\n",
    "    dirpath = \"/raid/data/data/VC/dc_tts/static/audios/\"\n",
    "    headingsNewsDir = '/raid/data/data/VC/dc_tts/static/generated/'\n",
    "    generatedFile = \"combined_news_file\"\n",
    "    text = text_['text_voice']\n",
    "    filenames = [\"/raid/data/data/VC/dc_tts/static/audios/\"+str(idx)+\".wav\" for idx, chunk in enumerate(chunks)]\n",
    "    #print(\"[/home/stock/jupyter_notebook/DeepLearningExamples/PyTorch/SpeechSynthesis/Tacotron2/static/audios/+str(idx)+.wav for idx, chunk in enume\\n\\n\")\n",
    "    print(filenames)\n",
    "    #filenameswithbeep = []\n",
    "    combined = AudioSegment.empty()\n",
    "    #for filename in filenames:\n",
    "    #        audiofilename = AudioSegment.from_wav(filename)\n",
    "    #        filenameswithbeep.extend([audiofilename])\n",
    "\n",
    "    #print(filenameswithbeep)\n",
    "\n",
    "    for fname in filenames:\n",
    "        combined += AudioSegment.from_wav(fname)\n",
    "\n",
    "    try:\n",
    "        output_name = str(random.randint(1,10000))\n",
    "        os.system('rm '+headingsNewsDir + generatedFile+str(output_name)+'.wav')\n",
    "\n",
    "       # output_name=text[:10].replace(' ','_')+'...'\n",
    "    except:\n",
    "        output_name = str(random.randint(1,10000))\n",
    "    #os.system('rm '+headingsNewsDir + generatedFile+str(output_name)+'.wav')\n",
    "    combined.export(headingsNewsDir + generatedFile+str(output_name)+'.wav', format=\"wav\")\n",
    "    print(\"---------------\",generatedFile+str(output_name))\n",
    "    return  generatedFile+str(output_name)\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(host='0.0.0.0', port=5000, threaded=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
